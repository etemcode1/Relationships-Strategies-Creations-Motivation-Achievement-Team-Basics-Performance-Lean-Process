Here are **5 more advanced and distinct code examples** related to **data corruption detection, proactive defense, and robust countermeasures** for ensuring system reliability and integrity. These examples explore more complex mechanisms such as distributed systems, blockchain, machine learning, and anomaly detection techniques to deliver fantastic value.

---

### 1. **Blockchain-Based Data Integrity for Distributed Systems (Solidity + JavaScript)**  
This example uses a simple blockchain smart contract to store hashes of data, ensuring immutability and tamper-proofing for distributed systems.

**Smart Contract (Solidity):**

```solidity
pragma solidity ^0.8.0;

contract DataIntegrity {
    struct DataRecord {
        string dataHash;
        uint timestamp;
    }

    mapping(uint => DataRecord) public dataRecords;
    uint public recordCount = 0;

    function addDataRecord(string memory dataHash) public {
        recordCount++;
        dataRecords[recordCount] = DataRecord(dataHash, block.timestamp);
    }

    function getDataRecord(uint recordId) public view returns (string memory, uint) {
        return (dataRecords[recordId].dataHash, dataRecords[recordId].timestamp);
    }
}
```

**Frontend (JavaScript):**

```javascript
const Web3 = require('web3');
const contractABI = [...]  // ABI generated by Solidity
const contractAddress = "0x...";  // Deployed contract address

async function storeDataHash(data) {
    const web3 = new Web3('http://localhost:8545');
    const contract = new web3.eth.Contract(contractABI, contractAddress);
    const dataHash = web3.utils.sha3(data);

    await contract.methods.addDataRecord(dataHash).send({ from: '0xYourAddress' });
    console.log("Data hash stored on blockchain:", dataHash);
}
```

This ensures that the integrity of data across distributed systems is **immutable and tamper-proof** through blockchain technology.

---

### 2. **Machine Learning Anomaly Detection for Data Corruption (Python + Scikit-learn)**  
This example leverages machine learning to automatically detect data anomalies, which could indicate corruption, in large datasets using an Isolation Forest.

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest

# Simulating some data (clean + corrupted)
data = pd.DataFrame({
    'feature1': np.random.normal(50, 10, 1000),
    'feature2': np.random.normal(60, 12, 1000),
    'feature3': np.random.normal(70, 15, 1000)
})
# Introduce some corruption
data.loc[990:999, 'feature1'] = 9999

# Train Isolation Forest to detect anomalies
clf = IsolationForest(contamination=0.01)
data['anomaly_score'] = clf.fit_predict(data[['feature1', 'feature2', 'feature3']])

# Mark and count anomalies
corrupted_rows = data[data['anomaly_score'] == -1]
print(f"Number of corrupted rows detected: {len(corrupted_rows)}")
```

**Machine learning** techniques like this provide proactive detection of corrupted data, particularly useful for large datasets.

---

### 3. **Proactive Redundancy Check with RAID Configuration (Bash + Linux RAID)**  
This example demonstrates a proactive redundancy mechanism using **RAID (Redundant Array of Independent Disks)** to ensure data integrity across multiple disks, useful in server environments.

```bash
# Create RAID 1 (mirroring) to prevent data loss and corruption
sudo mdadm --create --verbose /dev/md0 --level=1 --raid-devices=2 /dev/sda1 /dev/sdb1

# Check RAID status periodically
cat << 'EOF' > /usr/local/bin/check_raid.sh
#!/bin/bash
if grep -q '\[UU\]' /proc/mdstat; then
  echo "RAID is healthy"
else
  echo "RAID array failure detected!"
  # Trigger proactive response (e.g., alert or backup)
fi
EOF

# Schedule regular RAID health checks
echo "*/30 * * * * root /usr/local/bin/check_raid.sh" | sudo tee -a /etc/crontab
```

This ensures that **data redundancy and integrity** are maintained in storage systems, with proactive monitoring to detect any disk failures.

---

### 4. **Distributed Data Replication and Integrity Verification (Go + gRPC)**  
This example sets up a distributed data replication system using **gRPC** and verifies data integrity by comparing cryptographic hashes across distributed nodes.

**Server (Go):**

```go
package main

import (
	"crypto/sha256"
	"fmt"
	"log"
	"net"
	"google.golang.org/grpc"
)

type dataServer struct {
	data string
	hash string
}

func (s *dataServer) StoreData(data string) {
	s.data = data
	s.hash = fmt.Sprintf("%x", sha256.Sum256([]byte(data)))
}

func (s *dataServer) VerifyIntegrity(receivedHash string) bool {
	return receivedHash == s.hash
}

func main() {
	// gRPC server setup omitted for brevity
	listener, err := net.Listen("tcp", ":50051")
	if err != nil {
		log.Fatalf("Failed to listen: %v", err)
	}
	grpcServer := grpc.NewServer()
	// Register and run the server
}
```

**Client (Go):**

```go
package main

import (
	"crypto/sha256"
	"fmt"
	"google.golang.org/grpc"
)

func main() {
	conn, err := grpc.Dial("localhost:50051", grpc.WithInsecure())
	if err != nil {
		log.Fatalf("Failed to connect: %v", err)
	}
	defer conn.Close()

	data := "DistributedData"
	hash := fmt.Sprintf("%x", sha256.Sum256([]byte(data)))

	// Call the gRPC server to store data and verify integrity
}
```

**gRPC** ensures **high-performance communication** between distributed systems, and cryptographic hashing ensures that replicated data is consistent and uncorrupted.

---

### 5. **Proactive Content Validation in Real-Time Web Apps (React + GraphQL + Node.js)**  
This example implements a **real-time web application** that validates incoming user-generated content for corruption using content signature verification.

**Backend (Node.js + GraphQL):**

```javascript
const { ApolloServer, gql } = require('apollo-server');
const crypto = require('crypto');

// Sample schema and data signature verification
const typeDefs = gql`
  type Query {
    validateContent(content: String!, signature: String!): String
  }
`;

const resolvers = {
  Query: {
    validateContent: (_, { content, signature }) => {
      const computedSignature = crypto.createHash('sha256').update(content).digest('hex');
      return computedSignature === signature ? "Content is valid" : "Corrupted content detected";
    },
  },
};

const server = new ApolloServer({ typeDefs, resolvers });
server.listen().then(({ url }) => console.log(`Server ready at ${url}`));
```

**Frontend (React + Apollo Client):**

```javascript
import { gql, useQuery } from '@apollo/client';

const VALIDATE_CONTENT = gql`
  query ValidateContent($content: String!, $signature: String!) {
    validateContent(content: $content, signature: $signature)
  }
`;

function App() {
  const content = "User-generated content";
  const signature = CryptoJS.SHA256(content).toString();

  const { loading, error, data } = useQuery(VALIDATE_CONTENT, {
    variables: { content, signature },
  });

  if (loading) return <p>Loading...</p>;
  if (error) return <p>Error: {error.message}</p>;

  return <p>{data.validateContent}</p>;
}

export default App;
```

This ensures real-time validation of **user-generated content** in a web application, with quick detection of corruption and response mechanisms.

---

### **Suggested Smart File Name**:  
**"Advanced_Distributed_Data_Integrity_Proactive_Detection_CorruptionDefense"**

These additional examples provide a range of sophisticated approaches for detecting and responding to data corruption, including **blockchain, machine learning, RAID, gRPC-based distributed systems, and real-time content validation**, offering high value for ensuring system reliability and data accuracy.
